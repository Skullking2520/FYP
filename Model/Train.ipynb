{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3ccf3dda-3a3d-45f6-a251-acc92d0042f2",
            "metadata": {},
            "source": [
                "import torch\n",
                "print(\"CUDA available:\", torch.cuda.is_available())\n",
                "print(\"Device:\", torch.cuda.get_device_name(0))"
            ],
            "outputs": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "202b8721-0ef5-4851-b8d0-279e26ae9e1d",
            "metadata": {},
            "source": [
                "!pip install transformers==4.44.0\n",
                "!pip install peft==0.13.0\n",
                "!pip install accelerate==0.33.0\n",
                "!pip install trl==0.10.1\n",
                "!pip install bitsandbytes==0.43.1\n",
                "!pip install datasets"
            ],
            "outputs": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4f509157-1fa9-40bf-9483-400bf6c55398",
            "metadata": {},
            "source": [
                "import torch\n",
                "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
                "from peft import LoraConfig, get_peft_model\n",
                "from trl import SFTTrainer\n",
                "from transformers import TrainingArguments\n",
                "import json\n",
                "from datasets import Dataset\n",
                "\n",
                "print(\"CUDA:\", torch.cuda.is_available(), torch.cuda.get_device_name(0))\n",
                "\n",
                "# 1) Load base model (GPU + 4-bit quantization)\n",
                "BASE_MODEL = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
                "\n",
                "bnb_config = BitsAndBytesConfig(\n",
                "    load_in_4bit=True,\n",
                "    bnb_4bit_use_double_quant=True,\n",
                "    bnb_4bit_quant_type=\"nf4\",\n",
                "    bnb_4bit_compute_dtype=torch.bfloat16\n",
                ")\n",
                "\n",
                "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
                "tokenizer.pad_token = tokenizer.eos_token\n",
                "\n",
                "model = AutoModelForCausalLM.from_pretrained(\n",
                "    BASE_MODEL,\n",
                "    quantization_config=bnb_config,\n",
                "    device_map=\"auto\",\n",
                ")\n",
                "\n",
                "# 2) Configure LoRA\n",
                "lora_config = LoraConfig(\n",
                "    r=8,\n",
                "    lora_alpha=16,\n",
                "    lora_dropout=0.05,\n",
                "    bias=\"none\",\n",
                "    task_type=\"CAUSAL_LM\",\n",
                "    target_modules=[\n",
                "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
                "        \"gate_proj\", \"up_proj\", \"down_proj\",\n",
                "    ],\n",
                ")\n",
                "\n",
                "model = get_peft_model(model, lora_config)\n",
                "model.print_trainable_parameters()\n",
                "\n",
                "# 3) Load training data\n",
                "SEED_PATH = r\"C:\\Users\\Junsoo_Hyun\\Jupiter\\FYP\\Model\\skill_extraction_llama32_1B_synthetic_filtered_v2.jsonl\"\n",
                "\n",
                "records = []\n",
                "with open(SEED_PATH, \"r\", encoding=\"utf-8\") as f:\n",
                "    for line in f:\n",
                "        if line.strip():\n",
                "            records.append(json.loads(line))\n",
                "\n",
                "dataset = Dataset.from_list(records)\n",
                "\n",
                "def format_example(ex):\n",
                "    text = (\n",
                "        f\"{ex['instruction']}\\n\\n\"\n",
                "        f\"Student text:\\n{ex['input']}\\n\\n\"\n",
                "        f\"JSON: {ex['output']}\"\n",
                "    )\n",
                "    return [text]\n",
                "\n",
                "# 4) Training configuration\n",
                "OUTPUT_DIR = r\"C:\\Users\\Junsoo_Hyun\\Jupiter\\FYP\\Model\\skill-extractor-1B\"\n",
                "\n",
                "training_args = TrainingArguments(\n",
                "    output_dir=OUTPUT_DIR,\n",
                "    per_device_train_batch_size=1,\n",
                "    gradient_accumulation_steps=4,\n",
                "    num_train_epochs=2,\n",
                "    learning_rate=2e-4,\n",
                "    logging_steps=1,\n",
                "    save_strategy=\"epoch\",\n",
                "    fp16=True,\n",
                "    report_to=\"none\",\n",
                ")\n",
                "\n",
                "trainer = SFTTrainer(\n",
                "    model=model,\n",
                "    args=training_args,\n",
                "    train_dataset=dataset,\n",
                "    formatting_func=format_example,\n",
                ")\n",
                "\n",
                "trainer.train()\n",
                "\n",
                "trainer.model.save_pretrained(OUTPUT_DIR)\n",
                "tokenizer.save_pretrained(OUTPUT_DIR)\n",
                "\n",
                "print(\"GPU QLoRA fine-tuning complete.\")"
            ],
            "outputs": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7046ab83-c37c-43e2-af4c-5a3a25e16632",
            "metadata": {},
            "source": [
                "# skill_extractor_v1.py\n",
                "import torch\n",
                "import json\n",
                "import ast\n",
                "import difflib\n",
                "import pandas as pd\n",
                "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
                "from peft import PeftModel\n",
                "\n",
                "BASE_MODEL = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
                "ADAPTER_DIR = r\"C:\\Users\\Junsoo_Hyun\\Jupiter\\FYP\\Model\\skill-extractor-1B\"\n",
                "\n",
                "bnb_config = BitsAndBytesConfig(\n",
                "    load_in_4bit=True,\n",
                "    bnb_4bit_use_double_quant=True,\n",
                "    bnb_4bit_quant_type=\"nf4\",\n",
                "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
                ")\n",
                "\n",
                "print(\"CUDA:\", torch.cuda.is_available(), torch.cuda.get_device_name(0))\n",
                "\n",
                "tokenizer = AutoTokenizer.from_pretrained(ADAPTER_DIR)\n",
                "if tokenizer.pad_token is None:\n",
                "    tokenizer.pad_token = tokenizer.eos_token\n",
                "\n",
                "base_model = AutoModelForCausalLM.from_pretrained(\n",
                "    BASE_MODEL,\n",
                "    quantization_config=bnb_config,\n",
                "    device_map={\"\": \"cuda\"},\n",
                ")\n",
                "\n",
                "model = PeftModel.from_pretrained(base_model, ADAPTER_DIR)\n",
                "model.eval()\n",
                "\n",
                "skills_df = pd.read_csv(\"skills_master.csv\")\n",
                "skills_df[\"skill_name\"] = skills_df[\"skill_name\"].astype(str)\n",
                "master_names = skills_df[\"skill_name\"].tolist()\n",
                "master_names_lower = [n.lower() for n in master_names]\n",
                "lower_to_canonical = {n.lower(): n for n in master_names}\n",
                "\n",
                "def parse_model_output(text: str):\n",
                "    s = text.strip()\n",
                "    for parser in (json.loads, ast.literal_eval):\n",
                "        try:\n",
                "            obj = parser(s)\n",
                "            if isinstance(obj, list):\n",
                "                if all(isinstance(x, dict) for x in obj):\n",
                "                    return obj\n",
                "                if all(isinstance(x, str) for x in obj):\n",
                "                    out = []\n",
                "                    for name in obj:\n",
                "                        out.append({\"skill_name\": name, \"explanation\": \"\"})\n",
                "                    return out\n",
                "        except Exception:\n",
                "            continue\n",
                "    objs = []\n",
                "    n = len(s)\n",
                "    i = 0\n",
                "    while i < n:\n",
                "        if s[i] == \"{\":\n",
                "            depth = 0\n",
                "            start = i\n",
                "            end = None\n",
                "            for j in range(i, n):\n",
                "                if s[j] == \"{\":\n",
                "                    depth += 1\n",
                "                elif s[j] == \"}\":\n",
                "                    depth -= 1\n",
                "                    if depth == 0:\n",
                "                        end = j\n",
                "                        break\n",
                "            if end is None:\n",
                "                break\n",
                "            chunk = s[start:end+1]\n",
                "            try:\n",
                "                obj = json.loads(chunk)\n",
                "                if isinstance(obj, dict):\n",
                "                    objs.append(obj)\n",
                "            except Exception:\n",
                "                pass\n",
                "            i = end + 1\n",
                "        else:\n",
                "            i += 1\n",
                "    return objs\n",
                "\n",
                "def map_to_master(name: str, cutoff: float = 0.6):\n",
                "    if not name:\n",
                "        return None\n",
                "    key = str(name).strip().lower()\n",
                "    if not key:\n",
                "        return None\n",
                "    if key in lower_to_canonical:\n",
                "        return lower_to_canonical[key]\n",
                "    match = difflib.get_close_matches(key, master_names_lower, n=1, cutoff=cutoff)\n",
                "    if not match:\n",
                "        return None\n",
                "    return lower_to_canonical[match[0]]\n",
                "\n",
                "def extract_skills(student_text: str) -> str:\n",
                "    instruction = \"Extract relevant skills from the student text and return a JSON array with fields: skill_name and explanation.\"\n",
                "    prompt = instruction + \"\\n\\nStudent text:\\n\" + student_text + \"\\n\\nJSON: \"\n",
                "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
                "    with torch.no_grad():\n",
                "        outputs = model.generate(\n",
                "            **inputs,\n",
                "            max_new_tokens=256,\n",
                "            do_sample=False,\n",
                "            eos_token_id=tokenizer.eos_token_id,\n",
                "            temperature=1.0,\n",
                "            top_p=1.0,\n",
                "        )\n",
                "    gen_ids = outputs[0, inputs[\"input_ids\"].shape[1]:]\n",
                "    completion = tokenizer.decode(gen_ids, skip_special_tokens=True)\n",
                "    raw_list = parse_model_output(completion)\n",
                "    if not raw_list:\n",
                "        print(\"RAW COMPLETION (for debug):\", completion)\n",
                "    mapped = []\n",
                "    seen = set()\n",
                "    for item in raw_list:\n",
                "        if isinstance(item, dict):\n",
                "            raw_name = item.get(\"skill_name\", \"\")\n",
                "            explanation = str(item.get(\"explanation\", \"\")).strip()\n",
                "        else:\n",
                "            raw_name = str(item)\n",
                "            explanation = \"\"\n",
                "        canonical = map_to_master(raw_name)\n",
                "        if not canonical:\n",
                "            continue\n",
                "        if not explanation:\n",
                "            explanation = \"This skill is relevant to the described activities in the student text.\"\n",
                "        if canonical in seen:\n",
                "            continue\n",
                "        seen.add(canonical)\n",
                "        row = skills_df.loc[skills_df[\"skill_name\"] == canonical]\n",
                "        skill_id = None\n",
                "        if not row.empty and \"skill_id\" in row.columns:\n",
                "            skill_id = str(row.iloc[0][\"skill_id\"])\n",
                "        out_obj = {\"skill_name\": canonical, \"explanation\": explanation}\n",
                "        if skill_id is not None:\n",
                "            out_obj[\"skill_id\"] = skill_id\n",
                "        mapped.append(out_obj)\n",
                "    return json.dumps(mapped, ensure_ascii=False)\n",
                "\n",
                "test_text = (\n",
                "    \"Since childhood, I have enjoyed solving logic puzzles and brain teasers. \"\n",
                "    \"I often spend weekends working through puzzle books and online logic games, \"\n",
                "    \"trying to find patterns and efficient solutions.\"\n",
                ")\n",
                "\n",
                "print(extract_skills(test_text))\n"
            ],
            "outputs": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "aaf8f6fa-283d-49ba-9268-5d6d8727f8f1",
            "metadata": {},
            "source": [
                "# skill_extractor_final.py\n",
                "import torch\n",
                "import json\n",
                "import difflib\n",
                "import pandas as pd\n",
                "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
                "from peft import PeftModel\n",
                "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                "from sklearn.metrics.pairwise import cosine_similarity\n",
                "\n",
                "BASE_MODEL = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
                "ADAPTER_DIR = r\"C:\\Users\\Junsoo_Hyun\\Jupiter\\FYP\\Model\\skill-extractor-1B\"\n",
                "\n",
                "bnb_config = BitsAndBytesConfig(\n",
                "    load_in_4bit=True,\n",
                "    bnb_4bit_use_double_quant=True,\n",
                "    bnb_4bit_quant_type=\"nf4\",\n",
                "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
                ")\n",
                "\n",
                "print(\"CUDA:\", torch.cuda.is_available(), torch.cuda.get_device_name(0))\n",
                "\n",
                "tokenizer = AutoTokenizer.from_pretrained(ADAPTER_DIR)\n",
                "if tokenizer.pad_token is None:\n",
                "    tokenizer.pad_token = tokenizer.eos_token\n",
                "\n",
                "base_model = AutoModelForCausalLM.from_pretrained(\n",
                "    BASE_MODEL,\n",
                "    quantization_config=bnb_config,\n",
                "    device_map={\"\": \"cuda\"},\n",
                ")\n",
                "\n",
                "model = PeftModel.from_pretrained(base_model, ADAPTER_DIR)\n",
                "model.eval()\n",
                "\n",
                "skills_df = pd.read_csv(\"skills_master.csv\")\n",
                "skills_df[\"skill_name\"] = skills_df[\"skill_name\"].astype(str)\n",
                "\n",
                "if \"skill_description\" in skills_df.columns:\n",
                "    skills_df[\"skill_description\"] = skills_df[\"skill_description\"].fillna(\"\").astype(str)\n",
                "else:\n",
                "    skills_df[\"skill_description\"] = \"\"\n",
                "\n",
                "skills_df[\"text_for_tfidf\"] = skills_df[\"skill_name\"] + \" \" + skills_df[\"skill_description\"]\n",
                "\n",
                "# Master skill names (used to filter final outputs)\n",
                "master_names = skills_df[\"skill_name\"].tolist()\n",
                "\n",
                "vectorizer = TfidfVectorizer(stop_words=\"english\", max_features=20000)\n",
                "skill_tfidf = vectorizer.fit_transform(skills_df[\"text_for_tfidf\"])\n",
                "\n",
                "def get_candidate_indices(student_text: str, top_k: int = 60, min_score: float = 0.02):\n",
                "    vec = vectorizer.transform([student_text])\n",
                "    scores = cosine_similarity(vec, skill_tfidf)[0]\n",
                "    idx_sorted = scores.argsort()[::-1]\n",
                "    selected = []\n",
                "    for i in idx_sorted:\n",
                "        if scores[i] < min_score:\n",
                "            break\n",
                "        selected.append(i)\n",
                "        if len(selected) >= top_k:\n",
                "            break\n",
                "    if not selected:\n",
                "        selected = idx_sorted[:top_k]\n",
                "    return selected, scores\n",
                "\n",
                "def normalize_json_array(text: str):\n",
                "    s = text.strip()\n",
                "    objs = []\n",
                "    n = len(s)\n",
                "    i = 0\n",
                "    while i < n:\n",
                "        if s[i] == \"{\":\n",
                "            depth = 0\n",
                "            start = i\n",
                "            end = None\n",
                "            for j in range(i, n):\n",
                "                if s[j] == \"{\":\n",
                "                    depth += 1\n",
                "                elif s[j] == \"}\":\n",
                "                    depth -= 1\n",
                "                    if depth == 0:\n",
                "                        end = j\n",
                "                        break\n",
                "            if end is None:\n",
                "                break\n",
                "            chunk = s[start:end+1]\n",
                "            try:\n",
                "                obj = json.loads(chunk)\n",
                "                if isinstance(obj, dict):\n",
                "                    objs.append(obj)\n",
                "            except Exception:\n",
                "                pass\n",
                "            i = end + 1\n",
                "        else:\n",
                "            i += 1\n",
                "    return objs\n",
                "\n",
                "def map_to_candidate(name: str, cand_names_lower, lower_to_cand, cutoff: float = 0.6):\n",
                "    if not name:\n",
                "        return None\n",
                "    key = str(name).strip().lower()\n",
                "    if not key:\n",
                "        return None\n",
                "    if key in lower_to_cand:\n",
                "        return lower_to_cand[key]\n",
                "    match = difflib.get_close_matches(key, cand_names_lower, n=1, cutoff=cutoff)\n",
                "    if not match:\n",
                "        return None\n",
                "    return lower_to_cand[match[0]]\n",
                "\n",
                "def extract_skills(\n",
                "    student_text: str,\n",
                "    top_k_candidates: int = 60,\n",
                "    min_candidate_score: float = 0.02,\n",
                "    min_skill_score: float = 0.05,\n",
                "    max_return_skills: int = 5,\n",
                ") -> str:\n",
                "    idx, scores = get_candidate_indices(student_text, top_k=top_k_candidates, min_score=min_candidate_score)\n",
                "    cand_df = skills_df.iloc[idx].reset_index(drop=True)\n",
                "\n",
                "    cand_names = cand_df[\"skill_name\"].tolist()\n",
                "    cand_names_lower = [n.lower() for n in cand_names]\n",
                "    lower_to_cand = {n.lower(): n for n in cand_names}\n",
                "    cand_scores = scores[idx]\n",
                "\n",
                "    score_by_name = {}\n",
                "    for name, sc in zip(cand_names, cand_scores):\n",
                "        if name not in score_by_name or sc > score_by_name[name]:\n",
                "            score_by_name[name] = sc\n",
                "\n",
                "    instruction = \"Extract relevant skills from the student text and return a JSON array with fields: skill_name and explanation.\"\n",
                "    skills_list_str = \"\\n\".join(f\"- {name}\" for name in cand_names)\n",
                "\n",
                "    prompt = (\n",
                "        instruction\n",
                "        + \"\\nReturn at most \"\n",
                "        + str(max_return_skills)\n",
                "        + \" skills. Only include skills that are clearly demonstrated in the student text. You must choose skill_name values only from the allowed list.\\n\\nAllowed skill_name values:\\n\"\n",
                "        + skills_list_str\n",
                "        + \"\\n\\nStudent text:\\n\"\n",
                "        + student_text\n",
                "        + \"\\n\\nJSON: \"\n",
                ")\n",
                "\n",
                "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
                "    with torch.no_grad():\n",
                "        outputs = model.generate(\n",
                "            **inputs,\n",
                "            max_new_tokens=256,\n",
                "            do_sample=False,\n",
                "            eos_token_id=tokenizer.eos_token_id,\n",
                ")\n",
                "\n",
                "    gen_ids = outputs[0, inputs[\"input_ids\"].shape[1]:]\n",
                "    completion = tokenizer.decode(gen_ids, skip_special_tokens=True)\n",
                "    raw_list = normalize_json_array(completion)\n",
                "\n",
                "    if not raw_list:\n",
                "        print(\"RAW COMPLETION (debug):\", completion)\n",
                "\n",
                "    mapped = []\n",
                "    seen = set()\n",
                "    for item in raw_list:\n",
                "        if not isinstance(item, dict):\n",
                "            continue\n",
                "\n",
                "        raw_name = item.get(\"skill_name\", \"\")\n",
                "        explanation = str(item.get(\"explanation\", \"\")).strip()\n",
                "\n",
                "        canonical = map_to_candidate(raw_name, cand_names_lower, lower_to_cand)\n",
                "        if not canonical:\n",
                "            continue\n",
                "        if not explanation:\n",
                "            continue\n",
                "\n",
                "        # Keep only skills that exist in the master list\n",
                "        if canonical not in master_names:\n",
                "            continue\n",
                "\n",
                "        sc = score_by_name.get(canonical, 0.0)\n",
                "        if sc < min_skill_score:\n",
                "            continue\n",
                "\n",
                "        if canonical in seen:\n",
                "            continue\n",
                "        seen.add(canonical)\n",
                "\n",
                "        row = cand_df.loc[cand_df[\"skill_name\"] == canonical]\n",
                "        skill_id = None\n",
                "        if not row.empty and \"skill_id\" in row.columns:\n",
                "            skill_id = str(row.iloc[0][\"skill_id\"])\n",
                "\n",
                "        out_obj = {\"skill_name\": canonical, \"explanation\": explanation}\n",
                "        if skill_id is not None:\n",
                "            out_obj[\"skill_id\"] = skill_id\n",
                "\n",
                "        mapped.append(out_obj)\n",
                "\n",
                "        if len(mapped) >= max_return_skills:\n",
                "            break\n",
                "\n",
                "    return json.dumps(mapped, ensure_ascii=False)\n",
                "\n",
                "test_text = (\n",
                "    \"Since childhood, I have enjoyed solving logic puzzles and brain teasers. \"\n",
                "    \"I often spend weekends working through puzzle books and online logic games, \"\n",
                "    \"trying to find patterns and efficient solutions.\"\n",
                ")\n",
                "\n",
                "print(extract_skills(test_text))"
            ],
            "outputs": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "be8379c1-1424-4cdc-bfb1-902f50f5521e",
            "metadata": {},
            "source": [],
            "outputs": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
